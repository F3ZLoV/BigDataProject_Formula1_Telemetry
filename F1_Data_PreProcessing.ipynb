{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T06:46:12.925442Z",
     "start_time": "2025-11-22T06:46:11.191679Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€ (clean output)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# === ì„¤ì • ===\n",
    "TARGET_YEARS = range(2018, 2025)  # 2018 ~ 2024\n",
    "MAX_ROUNDS = 24                   # F1 ìµœëŒ€ ë¼ìš´ë“œ ìˆ˜\n",
    "OUTPUT_DIR = \"f1_processed_warehouse\" # ì €ì¥ë  ë£¨íŠ¸ í´ë”\n",
    "\n",
    "# === [1] ë¼ìš´ë“œë³„ ì²˜ë¦¬ í•¨ìˆ˜ (Worker) ===\n",
    "def process_single_round(args):\n",
    "    year, round_num = args\n",
    "\n",
    "    # MongoDB ì—°ê²° (í”„ë¡œì„¸ìŠ¤ë³„ ê°œë³„ ì—°ê²° í•„ìš”)\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"f1_bigdata_db\"]\n",
    "    col_telemetry = db[\"telemetry_raw\"]\n",
    "\n",
    "    try:\n",
    "        # 1. í•´ë‹¹ ë¼ìš´ë“œ ë°ì´í„°ë§Œ ì¸ì¶œ\n",
    "        projection = {\n",
    "            \"_id\": 0,\n",
    "            \"Year\": 1, \"Round\": 1, \"Driver\": 1, \"LapNumber\": 1,\n",
    "            \"Speed\": 1, \"RPM\": 1, \"nGear\": 1, \"Throttle\": 1, \"Brake\": 1, \"DRS\": 1,\n",
    "            \"Distance\": 1, \"Time\": 1,\n",
    "            \"Compound\": 1, \"TyreLife\": 1\n",
    "        }\n",
    "\n",
    "        cursor = col_telemetry.find({\"Year\": year, \"Round\": round_num}, projection)\n",
    "        df_raw = pd.DataFrame(list(cursor))\n",
    "\n",
    "        if df_raw.empty:\n",
    "            return None # ë°ì´í„° ì—†ìœ¼ë©´ ìŠ¤í‚µ\n",
    "\n",
    "        # 2. ê¸°ë³¸ ì „ì²˜ë¦¬\n",
    "        df_raw.dropna(subset=['Speed', 'Distance', 'LapNumber'], inplace=True)\n",
    "        df_raw['nGear'] = df_raw['nGear'].fillna(0).astype(int)\n",
    "        df_raw['Brake'] = df_raw['Brake'].astype(int)\n",
    "        df_raw['DRS'] = df_raw['DRS'].fillna(0).astype(int)\n",
    "\n",
    "        # 3. ë°ì´í„° ë³´ê°„ (Resampling)\n",
    "        processed_laps = []\n",
    "        grouped = df_raw.groupby(['Driver', 'LapNumber']) # ì´ë¯¸ Year/RoundëŠ” í•„í„°ë§ë¨\n",
    "\n",
    "        for (driver, lap_num), group in grouped:\n",
    "            try:\n",
    "                # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬\n",
    "                group = group.drop_duplicates(subset=['Distance'])\n",
    "                if len(group) < 10 or group['Distance'].max() < 2000:\n",
    "                    continue\n",
    "\n",
    "                # ë³´ê°„ ê¸°ì¤€ì  (10m ë‹¨ìœ„)\n",
    "                max_dist = group['Distance'].max()\n",
    "                new_dist = np.arange(0, max_dist, 10)\n",
    "\n",
    "                # ë³´ê°„ í•¨ìˆ˜ ìƒì„±\n",
    "                # kind='linear'ê°€ ì†ë„/ì •í™•ë„ ë°¸ëŸ°ìŠ¤ê°€ ê°€ì¥ ì¢‹ìŒ\n",
    "                f_speed = interp1d(group['Distance'], group['Speed'], kind='linear', fill_value=\"extrapolate\")\n",
    "                f_rpm = interp1d(group['Distance'], group['RPM'], kind='linear', fill_value=\"extrapolate\")\n",
    "                f_throttle = interp1d(group['Distance'], group['Throttle'], kind='linear', fill_value=\"extrapolate\")\n",
    "                f_brake = interp1d(group['Distance'], group['Brake'], kind='nearest', fill_value=\"extrapolate\")\n",
    "                f_gear = interp1d(group['Distance'], group['nGear'], kind='nearest', fill_value=\"extrapolate\")\n",
    "                f_drs = interp1d(group['Distance'], group['DRS'], kind='nearest', fill_value=\"extrapolate\")\n",
    "\n",
    "                # DataFrame ìƒì„±\n",
    "                df_lap = pd.DataFrame({\n",
    "                    'Distance': new_dist,\n",
    "                    'Speed': f_speed(new_dist),\n",
    "                    'RPM': f_rpm(new_dist),\n",
    "                    'Throttle': f_throttle(new_dist),\n",
    "                    'Brake': f_brake(new_dist),\n",
    "                    'nGear': f_gear(new_dist),\n",
    "                    'DRS': f_drs(new_dist)\n",
    "                })\n",
    "\n",
    "                # ë©”íƒ€ë°ì´í„° í• ë‹¹\n",
    "                df_lap['Year'] = int(year)\n",
    "                df_lap['Round'] = int(round_num)\n",
    "                df_lap['Driver'] = int(driver) if str(driver).isdigit() else driver\n",
    "                df_lap['LapNumber'] = int(lap_num)\n",
    "\n",
    "                # íƒ€ì´ì–´ ì •ë³´\n",
    "                compound = group['Compound'].iloc[0] if 'Compound' in group.columns else 'UNKNOWN'\n",
    "                tyre_life = group['TyreLife'].iloc[0] if 'TyreLife' in group.columns else 0\n",
    "                df_lap['Compound'] = compound\n",
    "                df_lap['TyreLife'] = tyre_life\n",
    "\n",
    "                # LapTime ê³„ì‚°\n",
    "                lap_time = group['Time'].max() - group['Time'].min()\n",
    "                # Time ì»¬ëŸ¼ì´ float(ì´ˆ)ì¸ì§€ datetimeì¸ì§€ í™•ì¸ í•„ìš”. ë³´í†µ float ê°€ì •\n",
    "                # ë§Œì•½ ì—ëŸ¬ë‚˜ë©´ ì—¬ê¸° í™•ì¸ í•„ìš”\n",
    "                df_lap['LapTime_Sec'] = float(lap_time)\n",
    "\n",
    "                processed_laps.append(df_lap)\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not processed_laps:\n",
    "            return None\n",
    "\n",
    "        # ë³‘í•© ë° ì €ì¥\n",
    "        df_final = pd.concat(processed_laps, ignore_index=True)\n",
    "\n",
    "        # ë°ì´í„° íƒ€ì… ìµœì í™” (ìš©ëŸ‰ ì ˆì•½)\n",
    "        df_final['Speed'] = df_final['Speed'].astype('float32')\n",
    "        df_final['RPM'] = df_final['RPM'].astype('float32')\n",
    "        df_final['Throttle'] = df_final['Throttle'].astype('float32')\n",
    "        df_final['Distance'] = df_final['Distance'].astype('float32')\n",
    "\n",
    "        # Parquet Partition ì €ì¥ (Year/Round í´ë” ìë™ ìƒì„±)\n",
    "        save_path = f\"{OUTPUT_DIR}/year={year}/round={round_num}\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        file_name = f\"{save_path}/telemetry.parquet\"\n",
    "\n",
    "        # fastparquet ì—”ì§„ ì‚¬ìš© (ì—†ìœ¼ë©´ pyarrow ìë™ ì‚¬ìš©)\n",
    "        df_final.to_parquet(file_name, index=False, compression='snappy')\n",
    "\n",
    "        return f\"âœ… {year}-R{round_num}: ì €ì¥ ì™„ë£Œ ({len(df_final):,} rows)\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âŒ {year}-R{round_num} ì—ëŸ¬: {str(e)}\"\n",
    "    finally:\n",
    "        client.close()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# === [2] ë©”ì¸ ì‹¤í–‰ë¶€ (ë³‘ë ¬ ì²˜ë¦¬) ===\n",
    "if __name__ == \"__main__\":\n",
    "    start_total = time.time()\n",
    "\n",
    "    # ì‘ì—… ëª©ë¡ ìƒì„±\n",
    "    tasks = [(y, r) for y in TARGET_YEARS for r in range(1, MAX_ROUNDS + 1)]\n",
    "\n",
    "    print(f\"ğŸš€ F1 ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ({TARGET_YEARS[0]} ~ {TARGET_YEARS[-1]})\")\n",
    "    print(f\"ğŸ“‚ ì €ì¥ ê²½ë¡œ: ./{OUTPUT_DIR}/...\")\n",
    "    print(f\"ğŸ”¢ ì´ ì‘ì—… ìˆ˜: {len(tasks)} ê°œ ë¼ìš´ë“œ\")\n",
    "\n",
    "    # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ë³‘ë ¬ ì²˜ë¦¬\n",
    "    max_workers = max(1, os.cpu_count() - 2)  # ì—¬ìœ  ì½”ì–´ 2ê°œ ë‚¨ê¹€\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # tqdmìœ¼ë¡œ ì§„í–‰ë°” í‘œì‹œ\n",
    "        results = list(tqdm(executor.map(process_single_round, tasks), total=len(tasks), desc=\"Processing\"))\n",
    "\n",
    "    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "    success_count = sum(1 for r in results if r and \"âœ…\" in r)\n",
    "    print(f\"\\nğŸ ì‘ì—… ì™„ë£Œ! ì„±ê³µ: {success_count} / {len(tasks)}\")\n",
    "    print(f\"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {(time.time() - start_total)/60:.1f}ë¶„\")\n",
    "    print(f\"ğŸ’¡ ë°ì´í„° ë¡œë“œ ë°©ë²•: pd.read_parquet('{OUTPUT_DIR}')\")"
   ],
   "id": "b85ddd321a85316e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:52:16.081228Z",
     "start_time": "2025-11-22T06:46:19.270373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ë³‘ë ¬ ì²˜ë¦¬(Executor) ë¶€ë¶„ì„ ì¼ë°˜ forë¬¸ìœ¼ë¡œ ë³€ê²½í•œ ë””ë²„ê¹…ìš© ì½”ë“œ\n",
    "if __name__ == \"__main__\":\n",
    "    start_total = time.time()\n",
    "\n",
    "    tasks = [(y, r) for y in TARGET_YEARS for r in range(1, MAX_ROUNDS + 1)]\n",
    "\n",
    "    print(f\"ğŸš€ F1 ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ({TARGET_YEARS[0]} ~ {TARGET_YEARS[-1]}) - ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ\")\n",
    "    print(f\"ğŸ“‚ ì €ì¥ ê²½ë¡œ: ./{OUTPUT_DIR}/...\")\n",
    "\n",
    "    results = []\n",
    "    # tqdmìœ¼ë¡œ ê°ì‹¸ì„œ ì§„í–‰ ìƒí™© ë³´ê¸°\n",
    "    for task in tqdm(tasks, desc=\"Processing\"):\n",
    "        # ë³‘ë ¬ì´ ì•„ë‹Œ ì§ì ‘ í˜¸ì¶œ\n",
    "        res = process_single_round(task)\n",
    "        results.append(res)\n",
    "\n",
    "    success_count = sum(1 for r in results if r and \"âœ…\" in r)\n",
    "    print(f\"\\nğŸ ì‘ì—… ì™„ë£Œ! ì„±ê³µ: {success_count} / {len(tasks)}\")\n",
    "    print(f\"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {(time.time() - start_total)/60:.1f}ë¶„\")"
   ],
   "id": "4c3a4a57a706bd20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ F1 ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ (2018 ~ 2024) - ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ\n",
      "ğŸ“‚ ì €ì¥ ê²½ë¡œ: ./f1_processed_warehouse/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [2:05:56<00:00, 44.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ ì‘ì—… ì™„ë£Œ! ì„±ê³µ: 148 / 168\n",
      "â±ï¸ ì´ ì†Œìš” ì‹œê°„: 125.9ë¶„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training Dataset ìƒì„±",
   "id": "e403038ad7408a1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:52:59.658860Z",
     "start_time": "2025-11-22T11:52:43.003039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ì„¤ì •\n",
    "INPUT_DIR = \"f1_processed_warehouse\"\n",
    "OUTPUT_FILE = \"f1_training_dataset_v2.parquet\"\n",
    "\n",
    "def create_clean_dataset():\n",
    "    print(\"ğŸ“‚ ë°ì´í„° ì¬ë¡œë”© ë° ì •ë°€ í•„í„°ë§ ì‹œì‘...\")\n",
    "\n",
    "    # [ìˆ˜ì • í¬ì¸íŠ¸] ë¶ˆëŸ¬ì˜¬ ë•ŒëŠ” 'ì›ë³¸ ì»¬ëŸ¼ëª…'ì„ ì¨ì•¼ í•©ë‹ˆë‹¤. (_mean ì œê±°)\n",
    "    cols = [\n",
    "        'Year', 'Round', 'Driver', 'LapNumber',\n",
    "        'Speed', 'Throttle', 'Brake', 'TyreLife', 'Compound', 'LapTime_Sec'\n",
    "    ]\n",
    "\n",
    "    # 1. ë°ì´í„° ë¡œë“œ\n",
    "    try:\n",
    "        df = pd.read_parquet(INPUT_DIR, columns=cols)\n",
    "        print(f\"âœ… ë¡œë“œ ì™„ë£Œ: {len(df):,} í–‰ (Raw Telemetry)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. ë© ë‹¨ìœ„ ìš”ì•½ (Aggregating)\n",
    "    print(\"âš™ï¸ ë© ë‹¨ìœ„ ë°ì´í„° ì••ì¶• ë° ìš”ì•½ ì¤‘...\")\n",
    "    grouped = df.groupby(['Year', 'Round', 'Driver', 'LapNumber'])\n",
    "\n",
    "    train_df = grouped.agg({\n",
    "        'Speed': 'mean',\n",
    "        'Throttle': 'mean',\n",
    "        'Brake': 'mean',\n",
    "        'TyreLife': 'max',\n",
    "        'Compound': 'first',\n",
    "        'LapTime_Sec': 'max'\n",
    "    }).reset_index()\n",
    "\n",
    "    # ì»¬ëŸ¼ëª… ë³€ê²½ (ì—¬ê¸°ì„œ _meanì„ ë¶™ì—¬ì¤ë‹ˆë‹¤)\n",
    "    train_df.columns = [\n",
    "        'Year', 'Round', 'Driver', 'LapNumber',\n",
    "        'Speed_mean', 'Throttle_mean', 'Brake_mean',\n",
    "        'TyreLife_max', 'Compound', 'LapTime_Sec'\n",
    "    ]\n",
    "\n",
    "    # === [í•µì‹¬] 3. ì´ìƒì¹˜ ì œê±° (107% ë£° ì ìš©) ===\n",
    "    print(\"ğŸ§¹ ë¹„ì •ìƒ ë©(í”¼íŠ¸ìŠ¤íƒ‘, SC, ì•„ì›ƒë©) ì œê±° ì¤‘...\")\n",
    "\n",
    "    clean_laps = []\n",
    "\n",
    "    # ë¼ìš´ë“œë³„ ê·¸ë£¹í™”í•˜ì—¬ 107% ì»·ì˜¤í”„ ì ìš©\n",
    "    # (tqdmì„ ì“°ë©´ ì¢‹ì§€ë§Œ dependency ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ìƒëµí•˜ê±°ë‚˜ ê°„ë‹¨íˆ ë£¨í”„)\n",
    "    for (year, round_num), group in train_df.groupby(['Year', 'Round']):\n",
    "        # í•´ë‹¹ ë¼ìš´ë“œì˜ ì „ì²´ ë© ì¤‘ ê°€ì¥ ë¹ ë¥¸ ê¸°ë¡ ì°¾ê¸°\n",
    "        fastest_lap = group['LapTime_Sec'].min()\n",
    "\n",
    "        # 107% ë£°: 1ë“± ê¸°ë¡ë³´ë‹¤ 7% ì´ìƒ ëŠë¦¬ë©´ ì •ìƒì ì¸ ë ˆì´ìŠ¤ ë©ì´ ì•„ë‹˜ (í”¼íŠ¸ì¸/ì‚¬ê³  ë“±)\n",
    "        threshold = fastest_lap * 1.07\n",
    "\n",
    "        # í•„í„°ë§: ë„ˆë¬´ ëŠë¦° ë©(threshold ì´ˆê³¼) & ë„ˆë¬´ ë¹ ë¥¸ ì˜¤ë¥˜ ë©(50ì´ˆ ë¯¸ë§Œ) ì œê±°\n",
    "        valid_laps = group[\n",
    "            (group['LapTime_Sec'] <= threshold) &\n",
    "            (group['LapTime_Sec'] > 50)\n",
    "        ]\n",
    "        clean_laps.append(valid_laps)\n",
    "\n",
    "    if not clean_laps:\n",
    "        print(\"âŒ ìœ íš¨í•œ ë©ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¤€ì´ ë„ˆë¬´ ì—„ê²©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    train_df = pd.concat(clean_laps)\n",
    "\n",
    "    # 4. íƒ€ì´ì–´ ì¸ì½”ë”©\n",
    "    compound_map = {\n",
    "        'SOFT': 1, 'MEDIUM': 2, 'HARD': 3,\n",
    "        'INTERMEDIATE': 4, 'WET': 5, 'UNKNOWN': 0\n",
    "    }\n",
    "    # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ì²˜ë¦¬\n",
    "    train_df['Compound_Encoded'] = train_df['Compound'].astype(str).str.upper().map(compound_map).fillna(0).astype(int)\n",
    "\n",
    "    # íƒ€ì´ì–´ ì •ë³´ ì—†ëŠ” ë°ì´í„° ì‚­ì œ\n",
    "    train_df = train_df[train_df['Compound_Encoded'] != 0]\n",
    "\n",
    "    print(f\"âœ… ì •ì œ ì™„ë£Œ: {len(train_df):,} ë© (ì§„ì§œ ë ˆì´ì‹± ë©ë§Œ ë‚¨ê¹€)\")\n",
    "\n",
    "    # ì €ì¥\n",
    "    train_df.to_parquet(OUTPUT_FILE, index=False)\n",
    "    print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_clean_dataset()"
   ],
   "id": "7a09669b21f81b4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ì¬ë¡œë”© ë° ì •ë°€ í•„í„°ë§ ì‹œì‘...\n",
      "âœ… ë¡œë“œ ì™„ë£Œ: 80,378,016 í–‰ (Raw Telemetry)\n",
      "âš™ï¸ ë© ë‹¨ìœ„ ë°ì´í„° ì••ì¶• ë° ìš”ì•½ ì¤‘...\n",
      "ğŸ§¹ ë¹„ì •ìƒ ë©(í”¼íŠ¸ìŠ¤íƒ‘, SC, ì•„ì›ƒë©) ì œê±° ì¤‘...\n",
      "âœ… ì •ì œ ì™„ë£Œ: 73,241 ë© (ì§„ì§œ ë ˆì´ì‹± ë©ë§Œ ë‚¨ê¹€)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: f1_training_dataset_v2.parquet\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
